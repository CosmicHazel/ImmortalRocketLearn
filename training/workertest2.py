from typing import Any
import numpy

from redis import Redis

from rlgym.envs import Match
from rlgym.utils.gamestates import PlayerData, GameState
from rlgym.utils.terminal_conditions.common_conditions import GoalScoredCondition, TimeoutCondition
from rlgym.utils.reward_functions.default_reward import DefaultReward
from rlgym.utils.state_setters.default_state import DefaultState
from rlgym.utils.obs_builders.advanced_obs import AdvancedObs
from rlgym.utils.action_parsers.discrete_act import DiscreteAction
from rlgym_tools.extra_action_parsers.kbm_act import KBMAction

from training.parser import ImmortalAction

from rocket_learn.rollout_generator.redis_rollout_generator import RedisRolloutWorker


# rocket-learn always expects a batch dimension in the built observation
class ExpandAdvancedObs(AdvancedObs):
    def build_obs(self, player: PlayerData, state: GameState, previous_action: numpy.ndarray) -> Any:
        obs = super(ExpandAdvancedObs, self).build_obs(player, state, previous_action)
        return numpy.expand_dims(obs, 0)


if __name__ == "__main__":
    match = Match(
        game_speed=100,
        self_play=True,
        team_size=1,
        state_setter=DefaultState(),
        obs_builder=ExpandAdvancedObs(),
        action_parser=KBMAction(),
        terminal_conditions=[TimeoutCondition(round(2000)),
                             GoalScoredCondition()],
        reward_function=DefaultReward()
    )

    r = Redis(host="127.0.0.1", password="")
    RedisRolloutWorker(r, "example", match,
                       #current_version_prob=.95,
                       past_version_prob=.05
                       ).run()
